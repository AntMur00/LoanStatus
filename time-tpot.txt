5000 записей

5-50: 12:19
5-100: 40:58
10-50: 20:18
10:100: 1:00:24 (1:06:00 при 90%)

739
2458
1218

4415
	3624
8039

0 tpot model: generations=5, pop_size=50
Accuracy: 1.0000
Precision: 1.0000
Recall: 1.0000
F1-Score: 1.0000
ROC_AUC: 1.0000

Confusion Matrix:
 [[913   0]
 [  0 587]]

Classification Report:
               precision    recall  f1-score   support

           0       1.00      1.00      1.00       913
           1       1.00      1.00      1.00       587

    accuracy                           1.00      1500
   macro avg       1.00      1.00      1.00      1500
weighted avg       1.00      1.00      1.00      1500


Best pipeline steps:
1. MinMaxScaler()
2. RFE(estimator=ExtraTreesClassifier(max_features=0.4503212524738,
                                   min_samples_leaf=4, min_samples_split=7,
                                   n_jobs=1, random_state=42),
    step=0.9162776237062)
3. FeatureUnion(transformer_list=[('featureunion',
                                FeatureUnion(transformer_list=[('binarizer',
                                                                Binarizer(threshold=0.856281565145)),
                                                               ('pca',
                                                                PCA(n_components=0.5132293634216))])),
                               ('passthrough', Passthrough())])
4. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
5. XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=0.0153706668713, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0354272416933, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=10, max_leaves=None,
              min_child_weight=15, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=100, n_jobs=1, nthread=1, ...)
Accuracy: 1.0000
Precision: 1.0000
Recall: 1.0000
F1-Score: 1.0000
ROC_AUC: 1.0000

Confusion Matrix:
 [[152   0]
 [  0  98]]

Classification Report:
               precision    recall  f1-score   support

           0       1.00      1.00      1.00       152
           1       1.00      1.00      1.00        98

    accuracy                           1.00       250
   macro avg       1.00      1.00      1.00       250
weighted avg       1.00      1.00      1.00       250


-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

1 tpot model: generations=5, pop_size=100
Accuracy: 1.0000
Precision: 1.0000
Recall: 1.0000
F1-Score: 1.0000
ROC_AUC: 1.0000

Confusion Matrix:
 [[913   0]
 [  0 587]]

Classification Report:
               precision    recall  f1-score   support

           0       1.00      1.00      1.00       913
           1       1.00      1.00      1.00       587

    accuracy                           1.00      1500
   macro avg       1.00      1.00      1.00      1500
weighted avg       1.00      1.00      1.00      1500


Best pipeline steps:
1. MinMaxScaler()
2. RFE(estimator=ExtraTreesClassifier(max_features=0.4503212524738,
                                   min_samples_leaf=4, min_samples_split=7,
                                   n_jobs=1, random_state=42),
    step=0.9162776237062)
3. FeatureUnion(transformer_list=[('featureunion',
                                FeatureUnion(transformer_list=[('binarizer',
                                                                Binarizer(threshold=0.856281565145)),
                                                               ('pca',
                                                                PCA(n_components=0.5132293634216))])),
                               ('passthrough', Passthrough())])
4. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
5. XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=0.0153706668713, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0354272416933, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=10, max_leaves=None,
              min_child_weight=15, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=100, n_jobs=1, nthread=1, ...)
Accuracy: 1.0000
Precision: 1.0000
Recall: 1.0000
F1-Score: 1.0000
ROC_AUC: 1.0000

Confusion Matrix:
 [[152   0]
 [  0  98]]

Classification Report:
               precision    recall  f1-score   support

           0       1.00      1.00      1.00       152
           1       1.00      1.00      1.00        98

    accuracy                           1.00       250
   macro avg       1.00      1.00      1.00       250
weighted avg       1.00      1.00      1.00       250


-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

2 tpot model: generations=10, pop_size=50
Accuracy: 1.0000
Precision: 1.0000
Recall: 1.0000
F1-Score: 1.0000
ROC_AUC: 1.0000

Confusion Matrix:
 [[913   0]
 [  0 587]]

Classification Report:
               precision    recall  f1-score   support

           0       1.00      1.00      1.00       913
           1       1.00      1.00      1.00       587

    accuracy                           1.00      1500
   macro avg       1.00      1.00      1.00      1500
weighted avg       1.00      1.00      1.00      1500


Best pipeline steps:
1. MinMaxScaler()
2. RFE(estimator=ExtraTreesClassifier(max_features=0.4503212524738,
                                   min_samples_leaf=4, min_samples_split=7,
                                   n_jobs=1, random_state=42),
    step=0.9162776237062)
3. FeatureUnion(transformer_list=[('featureunion',
                                FeatureUnion(transformer_list=[('binarizer',
                                                                Binarizer(threshold=0.856281565145)),
                                                               ('pca',
                                                                PCA(n_components=0.5132293634216))])),
                               ('passthrough', Passthrough())])
4. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
5. XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=0.0153706668713, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0354272416933, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=10, max_leaves=None,
              min_child_weight=15, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=100, n_jobs=1, nthread=1, ...)
Accuracy: 1.0000
Precision: 1.0000
Recall: 1.0000
F1-Score: 1.0000
ROC_AUC: 1.0000

Confusion Matrix:
 [[152   0]
 [  0  98]]

Classification Report:
               precision    recall  f1-score   support

           0       1.00      1.00      1.00       152
           1       1.00      1.00      1.00        98

    accuracy                           1.00       250
   macro avg       1.00      1.00      1.00       250
weighted avg       1.00      1.00      1.00       250


-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

3 tpot model: generations=10, pop_size=100
Accuracy: 1.0000
Precision: 1.0000
Recall: 1.0000
F1-Score: 1.0000
ROC_AUC: 1.0000

Confusion Matrix:
 [[913   0]
 [  0 587]]

Classification Report:
               precision    recall  f1-score   support

           0       1.00      1.00      1.00       913
           1       1.00      1.00      1.00       587

    accuracy                           1.00      1500
   macro avg       1.00      1.00      1.00      1500
weighted avg       1.00      1.00      1.00      1500


Best pipeline steps:
1. MinMaxScaler()
2. RFE(estimator=ExtraTreesClassifier(max_features=0.4503212524738,
                                   min_samples_leaf=4, min_samples_split=7,
                                   n_jobs=1, random_state=42),
    step=0.9162776237062)
3. FeatureUnion(transformer_list=[('featureunion',
                                FeatureUnion(transformer_list=[('binarizer',
                                                                Binarizer(threshold=0.856281565145)),
                                                               ('pca',
                                                                PCA(n_components=0.5132293634216))])),
                               ('passthrough', Passthrough())])
4. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
5. XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              feature_weights=None, gamma=0.0153706668713, grow_policy=None,
              importance_type=None, interaction_constraints=None,
              learning_rate=0.0354272416933, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=10, max_leaves=None,
              min_child_weight=15, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=100, n_jobs=1, nthread=1, ...)
Accuracy: 1.0000
Precision: 1.0000
Recall: 1.0000
F1-Score: 1.0000
ROC_AUC: 1.0000

Confusion Matrix:
 [[152   0]
 [  0  98]]

Classification Report:
               precision    recall  f1-score   support

           0       1.00      1.00      1.00       152
           1       1.00      1.00      1.00        98

    accuracy                           1.00       250
   macro avg       1.00      1.00      1.00       250
weighted avg       1.00      1.00      1.00       250
