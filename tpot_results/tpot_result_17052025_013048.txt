1 tpot model: generations=5, pop_size=50
1. MaxAbsScaler()
2. VarianceThreshold(threshold=0.0003878045217)
3. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
4. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
5. DecisionTreeClassifier(max_depth=13, min_samples_leaf=8, min_samples_split=18,
                       random_state=42)
Precision: 0.0972
Recall: 0.0009
F1-Score: 0.0017
ROC_AUC: 0.6308
Confusion Matrix:
 [[213646     65]
 [  7977      7]]

Classification Report:
               precision    recall  f1-score   support

           0       0.96      1.00      0.98    213711
           1       0.10      0.00      0.00      7984

    accuracy                           0.96    221695
   macro avg       0.53      0.50      0.49    221695
weighted avg       0.93      0.96      0.95    221695


-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

2 tpot model: generations=5, pop_size=100
1. StandardScaler()
2. SelectFwe(alpha=0.0213232165019)
3. FeatureUnion(transformer_list=[('featureunion',
                                FeatureUnion(transformer_list=[('columnonehotencoder',
                                                                ColumnOneHotEncoder())])),
                               ('passthrough', Passthrough())])
4. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
5. QuadraticDiscriminantAnalysis(reg_param=0.8477020748925)
Precision: 0.0768
Recall: 0.1933
F1-Score: 0.1099
ROC_AUC: 0.6234
Confusion Matrix:
 [[195159  18552]
 [  6441   1543]]

Classification Report:
               precision    recall  f1-score   support

           0       0.97      0.91      0.94    213711
           1       0.08      0.19      0.11      7984

    accuracy                           0.89    221695
   macro avg       0.52      0.55      0.52    221695
weighted avg       0.94      0.89      0.91    221695


-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

3 tpot model: generations=10, pop_size=50
1. MaxAbsScaler()
2. VarianceThreshold(threshold=0.0003878045217)
3. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
4. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
5. DecisionTreeClassifier(max_depth=13, min_samples_leaf=8, min_samples_split=18,
                       random_state=42)
Precision: 0.0972
Recall: 0.0009
F1-Score: 0.0017
ROC_AUC: 0.6308
Confusion Matrix:
 [[213646     65]
 [  7977      7]]

Classification Report:
               precision    recall  f1-score   support

           0       0.96      1.00      0.98    213711
           1       0.10      0.00      0.00      7984

    accuracy                           0.96    221695
   macro avg       0.53      0.50      0.49    221695
weighted avg       0.93      0.96      0.95    221695


-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

4 tpot model: generations=10, pop_size=100
1. StandardScaler()
2. SelectFwe(alpha=0.0213232165019)
3. FeatureUnion(transformer_list=[('featureunion',
                                FeatureUnion(transformer_list=[('columnonehotencoder',
                                                                ColumnOneHotEncoder())])),
                               ('passthrough', Passthrough())])
4. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
5. QuadraticDiscriminantAnalysis(reg_param=0.8477020748925)
Precision: 0.0768
Recall: 0.1933
F1-Score: 0.1099
ROC_AUC: 0.6234
Confusion Matrix:
 [[195159  18552]
 [  6441   1543]]

Classification Report:
               precision    recall  f1-score   support

           0       0.97      0.91      0.94    213711
           1       0.08      0.19      0.11      7984

    accuracy                           0.89    221695
   macro avg       0.52      0.55      0.52    221695
weighted avg       0.94      0.89      0.91    221695

