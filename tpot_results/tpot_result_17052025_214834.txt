1 tpot model: generations=5, pop_size=50
1. MaxAbsScaler()
2. VarianceThreshold(threshold=0.0003878045217)
3. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
4. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
5. DecisionTreeClassifier(max_depth=13, min_samples_leaf=8, min_samples_split=18,
                       random_state=42)
Accuracy: 0.9637339588172941
Balanced Accuracy: 0.5003512670816128
Precision: 0.1111111111111111
Recall: 0.001002004008016032
F1-Score: 0.0019860973187686196
ROC_AUC: 0.6308112833820707
Confusion Matrix:
 [[213647     64]
 [  7976      8]]

Classification Report:
               precision    recall  f1-score   support

           0       0.96      1.00      0.98    213711
           1       0.11      0.00      0.00      7984

    accuracy                           0.96    221695
   macro avg       0.54      0.50      0.49    221695
weighted avg       0.93      0.96      0.95    221695


-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

2 tpot model: generations=5, pop_size=100
1. StandardScaler()
2. SelectFwe(alpha=0.0213232165019)
3. FeatureUnion(transformer_list=[('featureunion',
                                FeatureUnion(transformer_list=[('columnonehotencoder',
                                                                ColumnOneHotEncoder())])),
                               ('passthrough', Passthrough())])
4. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
5. QuadraticDiscriminantAnalysis(reg_param=0.8477020748925)
Accuracy: 0.8864250434155033
Balanced Accuracy: 0.5533337545565744
Precision: 0.07645696832356273
Recall: 0.19438877755511022
F1-Score: 0.10974790510200474
ROC_AUC: 0.6233666988533922
Confusion Matrix:
 [[194964  18747]
 [  6432   1552]]

Classification Report:
               precision    recall  f1-score   support

           0       0.97      0.91      0.94    213711
           1       0.08      0.19      0.11      7984

    accuracy                           0.89    221695
   macro avg       0.52      0.55      0.52    221695
weighted avg       0.94      0.89      0.91    221695


-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

3 tpot model: generations=10, pop_size=50
1. MaxAbsScaler()
2. VarianceThreshold(threshold=0.0003878045217)
3. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
4. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
5. DecisionTreeClassifier(max_depth=13, min_samples_leaf=8, min_samples_split=18,
                       random_state=42)
Accuracy: 0.9637339588172941
Balanced Accuracy: 0.5003512670816128
Precision: 0.1111111111111111
Recall: 0.001002004008016032
F1-Score: 0.0019860973187686196
ROC_AUC: 0.6308112833820707
Confusion Matrix:
 [[213647     64]
 [  7976      8]]

Classification Report:
               precision    recall  f1-score   support

           0       0.96      1.00      0.98    213711
           1       0.11      0.00      0.00      7984

    accuracy                           0.96    221695
   macro avg       0.54      0.50      0.49    221695
weighted avg       0.93      0.96      0.95    221695


-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

4 tpot model: generations=10, pop_size=100
1. StandardScaler()
2. SelectFwe(alpha=0.0213232165019)
3. FeatureUnion(transformer_list=[('featureunion',
                                FeatureUnion(transformer_list=[('columnonehotencoder',
                                                                ColumnOneHotEncoder())])),
                               ('passthrough', Passthrough())])
4. FeatureUnion(transformer_list=[('skiptransformer', SkipTransformer()),
                               ('passthrough', Passthrough())])
5. QuadraticDiscriminantAnalysis(reg_param=0.8477020748925)
Accuracy: 0.8864250434155033
Balanced Accuracy: 0.5533337545565744
Precision: 0.07645696832356273
Recall: 0.19438877755511022
F1-Score: 0.10974790510200474
ROC_AUC: 0.6233666988533922
Confusion Matrix:
 [[194964  18747]
 [  6432   1552]]

Classification Report:
               precision    recall  f1-score   support

           0       0.97      0.91      0.94    213711
           1       0.08      0.19      0.11      7984

    accuracy                           0.89    221695
   macro avg       0.52      0.55      0.52    221695
weighted avg       0.94      0.89      0.91    221695

